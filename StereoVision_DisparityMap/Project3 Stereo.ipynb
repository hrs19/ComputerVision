{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52c832f2",
   "metadata": {},
   "source": [
    "# Project 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158954b6",
   "metadata": {},
   "source": [
    "### Reading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f37bd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import scipy\n",
    "from scipy import signal as sig\n",
    "import random\n",
    "from scipy.linalg import svd\n",
    "cast_path = \"Data/cast\"\n",
    "cone_path = \"Data/cone\"\n",
    "\n",
    "# path = input('Enter 1 for DanaHall\\nEnter 2 for DanaOffice\\n')\n",
    "path = 2\n",
    "if path==1:\n",
    "    path = cast_path\n",
    "else:\n",
    "    path = cone_path\n",
    "    \n",
    "\n",
    "file_li = []    \n",
    "for file in os.listdir(path):\n",
    "    file_li.append(file)\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b48687",
   "metadata": {},
   "source": [
    "## Compute Harris and Non Max Supression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a98be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sobel_filter(img, axis):\n",
    "    kernel = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "    if axis == 'x':\n",
    "        kernel = np.transpose(kernel)\n",
    "    filtered = np.zeros_like(img, dtype=np.float32)\n",
    "    img = np.pad(img, 1, mode='edge')\n",
    "    for i in range(1, img.shape[0]-1):\n",
    "        for j in range(1, img.shape[1]-1):\n",
    "            filtered[i-1, j-1] = np.sum(kernel * img[i-1:i+2, j-1:j+2])\n",
    "    return filtered\n",
    "\n",
    "def filter_img(image, kernel):\n",
    "    # Get kernel dimensions\n",
    "    k_height, k_width = kernel.shape\n",
    "\n",
    "    k_pad = k_height//2\n",
    "    \n",
    "#     image = cv2.copyMakeBorder(image, k_pad, k_pad, k_pad, k_pad, cv2.BORDER_CONSTANT, value=0)\n",
    "    \n",
    "    # Get image dimensions\n",
    "    img_height, img_width = image.shape\n",
    "\n",
    "    # Create output image\n",
    "    output = np.zeros_like(image)\n",
    "\n",
    "    # Loop over image pixels\n",
    "    for y in range(k_height//2, img_height - k_height//2):\n",
    "        for x in range(k_width//2, img_width - k_width//2):\n",
    "            # Get the region of interest\n",
    "            roi = image[y-k_height//2:y+k_height//2+1, x-k_width//2:x+k_width//2+1]\n",
    "\n",
    "            # Apply the kernel to the ROI\n",
    "            filtered_pixel = (roi * kernel).sum()\n",
    "\n",
    "            # Set the output pixel value\n",
    "            output[y, x] = filtered_pixel\n",
    "\n",
    "    return output \n",
    "\n",
    "def compute_harris_r(img, ksize, k):\n",
    "\n",
    "    # Compute gradients in x and y direction\n",
    "    dx = sobel_filter(img, axis='x')\n",
    "    dy = sobel_filter(img, axis='y')\n",
    "    \n",
    "#     cv2.imshow('dx',dx)\n",
    "#     cv2.imshow('dy',dy)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "    # Compute products of gradients at each pixel\n",
    "    dx2 = dx ** 2\n",
    "    dy2 = dy ** 2\n",
    "    dxy = dx * dy\n",
    "\n",
    "    # Compute sum of products of gradients in local window\n",
    "    w = np.ones((ksize, ksize), np.float64)\n",
    "    sdx2 = filter_img(dx2, w)\n",
    "    sdy2 = filter_img(dy2, w)\n",
    "    sdxy = filter_img(dxy, w)\n",
    "    \n",
    "#     cv2.imshow('sdx2',sdx2)\n",
    "#     cv2.imshow('sdy2',sdy2)\n",
    "\n",
    "#     cv2.imshow('dxy',dxy)\n",
    "\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "    # Compute Harris R function\n",
    "    det = sdx2 * sdy2 - sdxy ** 2\n",
    "    trace = sdx2 + sdy2\n",
    "    r = det - k * trace ** 2\n",
    "    \n",
    "    \n",
    "    return r\n",
    "\n",
    "def non_max_suppression(img, size, threshold):\n",
    "    # Find local maxima above threshold\n",
    "    h, w = img.shape\n",
    "    maxima = []\n",
    "    w_o_nms = []\n",
    "    for y in range(size, h - size):\n",
    "        for x in range(size, w - size):\n",
    "            w_o_nms.append((x,y))\n",
    "            if img[y, x] > threshold and img[y, x] == np.max(img[y - size:y + size + 1, x - size:x + size + 1]):\n",
    "                maxima.append((x, y))\n",
    "\n",
    "    return maxima,w_o_nms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9c11f4",
   "metadata": {},
   "source": [
    "## Find and Plot correspondence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9044a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_correspondences(img1, corners1, img2, corners2, patch_size, ncc_threshold):\n",
    "    correspondences = []\n",
    "    for i in range(len(corners1)):\n",
    "        max_ncc = -1\n",
    "        best_match = None\n",
    "        for j in range(len(corners2)):\n",
    "            # Extract patches centered at corners\n",
    "            patch1 = img1[corners1[i][1]-patch_size//2 : corners1[i][1]+patch_size//2,\n",
    "                          corners1[i][0]-patch_size//2 : corners1[i][0]+patch_size//2]\n",
    "            patch2 = img2[corners2[j][1]-patch_size//2 : corners2[j][1]+patch_size//2,\n",
    "                          corners2[j][0]-patch_size//2 : corners2[j][0]+patch_size//2]\n",
    "            \n",
    "#             print(patch1)\n",
    "            # Compute normalized cross correlation (NCC)\n",
    "            ncc = np.sum((patch1 - np.mean(patch1)) * (patch2 - np.mean(patch2))) / \\\n",
    "                  (np.sqrt(np.sum((patch1 - np.mean(patch1)) ** 2)) * np.sqrt(np.sum((patch2 - np.mean(patch2)) ** 2)))\n",
    "            # Update best match if NCC is higher than threshold and previous matches\n",
    "            if ncc > max_ncc and ncc > ncc_threshold:\n",
    "                max_ncc = ncc\n",
    "                best_match = (i, j)\n",
    "        if best_match is not None:\n",
    "            correspondences.append(best_match)\n",
    "    return correspondences\n",
    "\n",
    "# correspondences = match_corners(img1, img2, corners1, corners2)\n",
    "# plot_correspondences(img1, img2, correspondences)\n",
    "def plot_correspondences(img1, corners1, img2, corners2, matches, title='Correspondences'):\n",
    "    # Create a new image with both images side by side\n",
    "    h, w = max(img1.shape[0], img2.shape[0]), img1.shape[1] + img2.shape[1]\n",
    "    new_img = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    new_img[:img1.shape[0], :img1.shape[1]] = img1#cv2.cvtColor(img1, cv2.COLOR_GRAY2RGB)\n",
    "    new_img[:img2.shape[0], img1.shape[1]:] = img2#cv2.cvtColor(img2, cv2.COLOR_GRAY2RGB)\n",
    "    cv2.imshow(title, new_img)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "    # Draw lines between matching corners\n",
    "    for i, match in enumerate(matches):\n",
    "        pt1 = tuple(corners1[match[0]])\n",
    "        pt2 = (corners2[match[1]][0]+img1.shape[1],corners2[match[1]][1]+ 0)\n",
    "        color = tuple(np.random.randint(0, 256, 3).tolist())\n",
    "#         cv2.circle(new_img, corners1[i], 5, color, 2)\n",
    "#         cv2.circle(new_img, (corners2[i][0]+img1.shape[1],corners2[i][1]), 5, color, 2)\n",
    "\n",
    "#         print(pt1)\n",
    "#         print(pt2)\n",
    "        cv2.line(new_img, pt1, pt2, color, 2)\n",
    "\n",
    "    \n",
    "    # Display the image with the correspondences\n",
    "    cv2.imshow(title, new_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "def plot_correspondences_ransac(img1, corners1, img2, corners2, title='Correspondences'):\n",
    "    # Create a new image with both images side by side\n",
    "    h, w = max(img1.shape[0], img2.shape[0]), img1.shape[1] + img2.shape[1]\n",
    "    new_img = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    new_img[:img1.shape[0], :img1.shape[1]] = img1#cv2.cvtColor(img1, cv2.COLOR_GRAY2RGB)\n",
    "    new_img[:img2.shape[0], img1.shape[1]:] = img2#cv2.cvtColor(img2, cv2.COLOR_GRAY2RGB)\n",
    "    cv2.imshow(title, new_img)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "    # Draw lines between matching corners\n",
    "    for i in range(len(corners1)):\n",
    "        pt1 = corners1[i]\n",
    "        pt2 = (corners2[i][0]+img1.shape[1],corners2[i][1])\n",
    "#         print(pt1,pt2)\n",
    "        color = tuple(np.random.randint(0, 256, 3).tolist())\n",
    "        cv2.circle(new_img, corners1[i], 5, color, 2)\n",
    "        cv2.circle(new_img, (corners2[i][0]+img1.shape[1],corners2[i][1]), 5, color, 2)\n",
    "#         print(pt1)\n",
    "#         print(pt2)\n",
    "        cv2.line(new_img, pt1, pt2, color, 2)\n",
    "    \n",
    "    \n",
    "    # Display the image with the correspondences\n",
    "    cv2.imshow(title, new_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78387c6f",
   "metadata": {},
   "source": [
    "### Computing the corners and getting matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5af723f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_factor = 1\n",
    "\n",
    "\n",
    "img1 = cv2.imread(f'{path}/'+file_li[0])\n",
    "img2 = cv2.imread(f'{path}/'+file_li[1])\n",
    "\n",
    "img1 = cv2.resize(img1,None,fx=scale_factor,fy=scale_factor,interpolation=cv2.INTER_LINEAR)\n",
    "img2 = cv2.resize(img2,None,fx=scale_factor,fy=scale_factor,interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "r1 = compute_harris_r(cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY), ksize=3, k=0.04)\n",
    "corners1,c1_wo = non_max_suppression(r1, size=5, threshold=0.01*r1.max())\n",
    "\n",
    "r2 = compute_harris_r(cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY), ksize=3, k=0.04)\n",
    "corners2,c2_wo = non_max_suppression(r2, size=5, threshold=0.01*r2.max())\n",
    "\n",
    "# Draw corners on the images\n",
    "#     img1_corners = cv2.cvtColor(img1, cv2.COLOR_GRAY2RGB)\n",
    "img1_corners = img1.copy()\n",
    "for corner in c1_wo:\n",
    "    cv2.circle(img1_corners, corner, 5, (0, 0, 255), 2)\n",
    "cv2.imshow('Image 1 Corners befor non max suppression', img1_corners)\n",
    "\n",
    "img1_corners = img1.copy()\n",
    "for corner in corners1:\n",
    "    cv2.circle(img1_corners, corner, 5, (0, 0, 255), 2)\n",
    "\n",
    "#     img2_corners = cv2.cvtColor(img2, cv2.COLOR_GRAY2RGB)\n",
    "img2_corners = img2.copy()\n",
    "\n",
    "for corner in corners2:\n",
    "    cv2.circle(img2_corners, corner, 5, (0, 0, 255), 2)\n",
    "\n",
    "# Display images with corners\n",
    "cv2.imshow('Image 1 Corners', img1_corners)\n",
    "cv2.imshow('Image 2 Corners', img2_corners)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "print('corners:',len(corners1),len(corners2))\n",
    "patch_size = 10\n",
    "ncc_threshold = 0.90\n",
    "matches = find_correspondences(cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY), corners1, cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY), corners2, patch_size, ncc_threshold)\n",
    "\n",
    "plot_correspondences(img1, corners1, img2, corners2, matches, title='Correspondences')    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62744994",
   "metadata": {},
   "source": [
    "## Computing F and epipolar lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8f4b183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_points(pts):\n",
    "\n",
    "    mean_ =np.mean(pts,axis=0)\n",
    "\n",
    "    #finding centre\n",
    "    u = pts[:,0] - mean_[0]\n",
    "    v = pts[:,1] - mean_[1]\n",
    "\n",
    "    sd_u = 1/np.std(pts[:,0])\n",
    "    sd_v = 1/np.std(pts[:,1])\n",
    "    Tscale = np.array([[sd_u,0,0],[0,sd_v,0],[0,0,1]])\n",
    "    Ta = np.array([[1,0,-mean_[0]],[0,1,-mean_[1]],[0,0,1]])\n",
    "    T = np.dot(Tscale,Ta)\n",
    "\n",
    "    pt = np.column_stack((pts,np.ones(len(pts))))\n",
    "    norm_pts = (np.dot(T,pt.T)).T\n",
    "\n",
    "    return norm_pts,T\n",
    "\n",
    "def estimate_F(img1_pts,img2_pts):\n",
    "\n",
    "    #normalize points\n",
    "    img1_pts,T1 = normalize_points(img1_pts)\n",
    "    img2_pts,T2 = normalize_points(img2_pts)\n",
    "\n",
    "    x1 = img1_pts[:,0]\n",
    "    y1 = img1_pts[:,1]\n",
    "    x1dash = img2_pts[:,0]\n",
    "    y1dash = img2_pts[:,1]\n",
    "    A = np.zeros((len(x1),9))\n",
    "\n",
    "    for i in range(len(x1)):\n",
    "        A[i] = np.array([x1dash[i]*x1[i],x1dash[i]*y1[i],x1dash[i], y1dash[i]*x1[i],y1dash[i]*y1[i],y1dash[i],x1[i],y1[i],1])\n",
    "\n",
    "    #taking SVD of A for estimation of F\n",
    "    U, S, V = np.linalg.svd(A,full_matrices=True)\n",
    "    F_est = V[-1, :]\n",
    "    F_est = F_est.reshape(3,3)\n",
    "\n",
    "    # Enforcing rank 2 for F\n",
    "    ua,sa,va = np.linalg.svd(F_est,full_matrices=True)\n",
    "    sa = np.diag(sa)\n",
    "\n",
    "    sa[2,2] = 0\n",
    "   \n",
    "\n",
    "    F = np.dot(ua,np.dot(sa,va))\n",
    "    # F, mask = cv2.findFundamentalMat(img1_pts,img2_pts,cv2.FM_LMEDS)\n",
    "    F = np.dot(T2.T, np.dot(F, T1))\n",
    "\n",
    "    return F\n",
    "\n",
    "def ransac_F(corners1,corners2,matches):\n",
    "    no_iter = 1000\n",
    "    threshold = 0.05\n",
    "    inliers = 0\n",
    "    pt1 = np.array([corners1[matches[idx][0]] for idx in range(len(matches))])\n",
    "    pt2 = np.array([corners2[matches[idx][1]] for idx in range(len(matches))])\n",
    "    n_rows = np.array(pt1).shape[0]\n",
    "\n",
    "    final_indices = []\n",
    "    for i in range(no_iter):\n",
    "        indices = []\n",
    "\n",
    "        #randomly select 8 points\n",
    "        random = np.random.choice(n_rows,size = 8)\n",
    "        img1_8pt = pt1[random]\n",
    "        img2_8pt = pt2[random]\n",
    "    \n",
    "        F_est = estimate_F(img1_8pt,img2_8pt)\n",
    "\n",
    "        for j in range(n_rows):\n",
    "            x1 = pt1[j]\n",
    "            x2 = pt2[j]\n",
    "\n",
    "            #error computation\n",
    "            pt1_ = np.array([x1[0],x1[1],1])\n",
    "            pt2_ = np.array([x2[0],x2[1],1])\n",
    "            error = np.dot(pt1_.T,np.dot(F_est,pt2_))\n",
    "            \n",
    "            if np.abs(error) < threshold:\n",
    "                indices.append(j)\n",
    "                \n",
    "        if len(indices) > inliers:\n",
    "            inliers = len(indices)\n",
    "            final_indices = indices\n",
    "            F = F_est\n",
    "\n",
    " \n",
    "    img1_points = pt1[final_indices]\n",
    "    img2_points = pt2[final_indices]\n",
    "\n",
    "    F_all_inliers = estimate_F(img1_points,img2_points)\n",
    "\n",
    "    return img1_points,img2_points, F,F_all_inliers\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def draw_lines(lines_set,image,points):\n",
    "    for line,pt in zip(lines_set,points):\n",
    "        x0,y0 = map(int, [0, -line[2]/line[1] ])\n",
    "        x1,y1 = map(int, [image.shape[1]-1, -line[2]/line[1] ])\n",
    "        img = cv2.line(image, (x0,y0), (x1,y1), (0,255,0) ,2)\n",
    "        img = cv2.circle(image, (int(pt[0]),int(pt[1])), 5, (0,255,0), 2)\n",
    "    return img\n",
    "\n",
    "def epipolar_lines(pts1_,pts2_,F,image1,image2):\n",
    "    lines1_,lines2_ = [], []\n",
    "    for i in range(len(pts1_)):\n",
    "        p1 = np.array([pts1_[i,0], pts1_[i,1], 1])\n",
    "        p2 = np.array([pts2_[i,0], pts2_[i,1], 1])\n",
    "    \n",
    "        lines1_.append(np.dot(F.T, p2))\n",
    "        lines2_.append(np.dot(F,p1))\n",
    "    img1 = draw_lines(lines1_,image1,pts1_)\n",
    "    img2 = draw_lines(lines2_,image2,pts2_)\n",
    "\n",
    "   \n",
    "\n",
    "    out = np.hstack((img1, img2))\n",
    "    cv2.imwrite(\"epipolar_lines.png\",out)\n",
    "    return lines1_,lines2_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb6ffc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts1_,pts2_, F,F_all_inliers = ransac_F(corners1,corners2,matches)\n",
    "F = F_all_inliers/F_all_inliers[2,2]\n",
    "\n",
    "lines1,lines2 = epipolar_lines(pts1_,pts2_,F,img1.copy(),img2.copy())\n",
    "plot_correspondences_ransac(img1, pts1_, img2, pts2_, title='Correspondences after Fundamental martix RANSAC')   \n",
    "\n",
    "\n",
    "\n",
    "gray1 = cv2.cvtColor(img1.copy(),cv2.COLOR_BGR2GRAY)\n",
    "gray2 = cv2.cvtColor(img2.copy(), cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea46cdc7",
   "metadata": {},
   "source": [
    "## Compute Dense Disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8648a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.color import rgb2gray, gray2rgb, hsv2rgb\n",
    "from skimage.transform import ProjectiveTransform\n",
    "\n",
    "def disp_map(imgL, imgR, block_size=5, search_range=56, lines2):\n",
    "    \n",
    "    # Convert images to grayscale\n",
    "    grayL = rgb2gray(imgL)\n",
    "    grayR = rgb2gray(imgR)\n",
    "    \n",
    "    epipolar_lines = lines2\n",
    "    \n",
    "    # Compute image size and block radius\n",
    "    h, w = grayL.shape\n",
    "    r = block_size // 2\n",
    "\n",
    "    ptsL = np.array([(x, y) for y in range(h) for x in range(w)])\n",
    "\n",
    "    h_disp = np.zeros((h, w))\n",
    "    v_disp = np.zeros((h, w))\n",
    "    c_disp = np.zeros((h, w, 3))\n",
    "    \n",
    "#     return epipolar_lines\n",
    "    \n",
    "\n",
    "    for i, ptL in enumerate(ptsL):\n",
    "\n",
    "        xL, yL = ptL\n",
    "        window_left = grayL[max(0, yL-r):min(h, yL+r+1), max(0, xL-r):min(w, xL+r+1)]\n",
    "\n",
    "        search_min = max(0, xL - search_range)\n",
    "        search_max = min(w, xL + search_range)\n",
    "\n",
    "        costs = []\n",
    "        for x_right in range(search_min, search_max):\n",
    "            window_right = grayR[max(0, yL-r):min(h, yL+r+1), max(0, x_right-r):min(w, x_right+r+1)]\n",
    "\n",
    "            window_size = min(window_left.shape[0], window_right.shape[0]), min(window_left.shape[1], window_right.shape[1])\n",
    "            window_left = window_left[:window_size[0], :window_size[1]]\n",
    "            window_right = window_right[:window_size[0], :window_size[1]]\n",
    "            \n",
    "            #Sum absolute difference\n",
    "            cost = np.sum(np.abs(window_left - window_right))\n",
    "\n",
    "            costs.append(cost)\n",
    "\n",
    "            \n",
    "        # Find the smallest SAD\n",
    "        best_match = np.argmin(costs)\n",
    "        \n",
    "        #x direction disparity\n",
    "        disparity = xL - (search_min + best_match)\n",
    "\n",
    "        \n",
    "        #Horizontal Disparity\n",
    "        h_disp[yL, xL] = disparity\n",
    "        \n",
    "        #Vertical Disparity\n",
    "        v_disp[yL, xL] = epipolar_lines[i][0][1]\n",
    "\n",
    "        # Color Disparity HSV \n",
    "        hue = 180 * (np.arctan2(epipolar_lines[i][0][1], disparity) + np.pi) / (2 * np.pi)\n",
    "        saturation = np.sqrt(disparity**2 + epipolar_lines[i][0][1]**2)\n",
    "        c_disp[yL, xL] = [hue, saturation, 1]\n",
    "\n",
    "\n",
    "    # Scale disp maps to 0, 255 range\n",
    "    h_disp = 255 * (h_disp - np.min(h_disp)) / (np.max(h_disp) - np.min(h_disp))\n",
    "    v_disp = 255 * (v_disp - np.min(v_disp)) / (np.max(v_disp) - np.min(v_disp))\n",
    "\n",
    "    return h_disp, v_disp, hsv2rgb(c_disp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b696a4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_disp, v_disp, c_disp = disp_map(img1, img2, lines2)\n",
    "\n",
    "cv2.imshow('Disparity Color Component', np.uint8(c_disp))\n",
    "cv2.imshow('Horizontal Disparity Component', np.uint8(h_disp))\n",
    "cv2.imshow('Vertical Disparity Component', np.uint8(v_disp))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
